            +--------------------+
            |        CS 140      |
            | PROJECT 1: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Mohamed Magdi <imohmaedpro@icloud.com>
Karim Alaa <karimalaa1912@gmail.com>
Youhanna Yousry <youhanna.yousry.2580@gmail.com>
Youssef Magdi <youssefmagdi1210@gmail.com>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct sleeping_thread {
  struct list_elem elem;
  struct thread* thread;
  int64_t wakeup_ticks;
};
A list entry added to sleeping_threads_list that contains mainly a pointer to the sleeping
thread and its wake up ticks.

static struct list sleeping_threads_list;
A list containing all the sleeping threads at a certain time.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

First we check whether the ticks (passed as paramter) is greater than 
the time elapsed since the start of the function, if yes interrupts are
disabled and the current thread is added with its corresponding wake-up
ticks to a sleeping threads list. Finally, it is blocked.
Interrupt handler checks wheter there is any threads ready to wake-up
by comparing its wake-up ticks with the current tick.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The sleeping threads list is ordered in incremental order of wake-up ticks
so each time the interrupt handler is called, we check wether the first 
thread wake-up time is less than or equal the current ticks. If yes, this
thread is unblocked and we check the next thread also and so on.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Since interrupts (external interrupts) are disabled, race conditions
shall not take place.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Timer interrupts cannot occur since external interrupts are disabled 
just before adding the thread to the list and blocking it.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design to reduce memory consumption; rather than adding 
64 bits integer to all threads, we created a separate struct (defined in 
timer.c file since it's not needed elsewhere) that adds the wake up ticks
to the sleeping thread.
Additionally, we found out that there is no need to allocate a memory place for
this struct in the heap and deallocate it later; when the thread is blocked
the function timer_sleep doesn't return until this thread wake up again.
Therefore, the struct never left the stack  all that time.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.

struct lock {
    .
    .
    struct list_elem elem;      /* List element for thread lock list*/
    int priority;               /* Maximum priority between threads */
  }

struct thread {
    .
    .
    int original_priority;
    struct lock *wait;                 /* Lock which thread waits for */
    struct list locks;                 /* List of owned locks */
    .
    .                 
  }

Three new members were added to struct thread, integer to save original
priority to revert after priority donation ends. Also, a list for owned
locks references and a pointer to the  lock which the  thread waits for
(if exits), by default its value is NULL.

Two new members were added to struct lock, an integer to save the owner
thread of the lock and a list element for list locks in struct thread.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.

- int priority (struct lock):
    Used to save the priority of waiting thread (donated or original).
- int original_priority (struct thread):
    Used to save the original priority of the thread. It is used to revert
    to it when the thread releases a lock.
- struct lock * wait (struct thread):
    Used  to  save  the  lock  which  thread  is  waiting  for  to  acquire.
    Also,  used  to  keep  track  of  nested  donations.
- struct list locks (struct thread):
    Used to keep  track of the thread's  current owned locks. Also, used  to
    update thread priority in case of donation.


- Nested Donations:

                        /----Lock1.holder     /----Lock2.holder     /---- Lock3.holder
       ____________    /     ____________    /     ____________    /     ____________
      |      A     | Lock 1 |     B      | Lock 2 |     C      | Lock 3 |      D     |
 ---- |        wait|------->|        wait|------->|        wait|------->|            |
      |   p = 100  |        |   p = 100  |        |   p = 100  |        |   p = 100  |
      | o_p = 100  |        |  o_p = 50  |        |  o_p = 60  |        |  o_p = 10  |
      |____________|        |____________|        |____________|        |____________|
         Thread A              Thread B              Thread C              Thread D

    o_p -> stands for original_priority in struct thread
    ALGORITHM:
        tmp = lock1
        for i in range depth
            if tmp.holder is NULL
                break
            else
                tmp.priority = thread.priority
                update_priority(tmp.holder)
                tmp = tmp.holder.wait

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

--  semaphores  : when sema_up() is called, it searches for the highest
                  priority thread among the list of waiters, this thread
                  gets unblocked and moved to ready list.

--     lock     : since locks are implemented using semaphores, the highest
                  priority thread gets unblocked in the same way.

-- cond variable: condition variables have a list of semaphores, so we search
                  for the thread with highest priority among all semaphore,
                  and this thread is unblocked.
-- After each of these conditions, a function call is made to thread_check_priority()
   which checks if the unblocked thread has a higher priority than the current thread
   and if so, thread_yield() is called to reschedule.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

- When lock_acquire() is called, the calling thread donates its priority to the lock,
  then calls thread_update_priority(lock->holder), which updates the lock holder's 
  priority. For nested donations, a loop was used. In each iteration, the variable
  struct lock * tmp is updated to tmp->holder->wait. In another way, it updates itself
  to the lock which the previous lock holder was waiting for. It donates its priority
  to that lock, and then calls thread_update_priority(tmp->holder) until it finds a
  holder thread with no waiting blovk (NULL), or to the required depth.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

- When lock_release() is called by a thread, it removes the lock from the list of 
  locks in struct thread. Then it updates its priority thorugh thread_update_priority()
  The function restores the thread priority into its original priority, and checks if
  it acquires any other locks that might increase its priority by donation.
  After that, sema_up() is called on the lock's semaphore, and by semaphore implementation
  it will wake up the higher-priority thread, which will lead to rescheduling and the
  higher-priority thread will acquire the lock.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

- If thread_set_priority() was called when another thread was editing priority thorugh
  donation. Interrupts were disabled during thread_set_priority() to avoid such behavior.
  However, in our implementation it was not necessary to disable interrupts for that case.
  Since priority donation updates the priority in struct lock, and thread_set_priority() 
  updates original_priority (in struct thread). Each of them update a differente variable,
  so no race condition may occurs. But we disabled interrupts to make sure that the priority
  of thread is actually updated (thread not blocked until priority is updated).

- A lock can be used to prevent race conditions on priority, when one thread is editing
  it, no other thread can. However, lock_acquire() itself disable interrupts.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

- When we donate the priority to locks instead of donating it directely to the thread,
  we eliminsted many race conditions may occur. Also, this implementation is easier as
  each thread only will keep track of its acquired locks, and whenever a high priority
  thread gets blocked by the lock, the priority of the locker holder will increase by
  donation.

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

A "real" uses the 32 bits representation of an int to represent 
a fixed point number.

typedef struct {
    int value;
} real;

Added to struct thread:
    /* Advanced Scheduler */
    int nice;                           /* How likely the thread will give up the cpu.*/
    real recent_cpu;                    /*estimate of recent cpu usage by the thread.*/

Added Global variable:
    real load_avg;                      /*estimate of the average load on the cpu.*/

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0   63  61  59     A
 4      1   0   0   62  61  59     A
 8      5   0   0   61  61  59     B
12      8   1   0   61  60  59     A
16      9   4   0   60  60  59     B 
20     12   5   0   60  59  59     A
24     13   8   0   59  59  59     C  
28     16   8   1   59  58  58     B
32     16   9   4   59  58  58     A
36     17  12   4   58  58  58     C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

When there is a tie in the priorities of two threads, choosing which thread
to run was no specified. So a FIFO policy was used in such case.
This does indeed match the behavior of our scheduler; when iterating over
the ready_list to pick the thread with highest priority, we use the condition
greater than (>) to update the maximum value, which leeds that the first thread
in the list which has the highest priority is the one served.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

Only the calculations of load_avg, recent_cpu and priorities are done 
inside the interrupt, which are a constant amount of computation.
Since the recent_cpu and priority has to be calculated for every thread,
only one loop was used, although they don't get updated always at the same tick.
A boolean value was used to update recent_cpu along with the priority
when the update conditions coincide.



---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

One downside of our implementation, it uses only a single queue 
for scheduling, and the Scheduler has to iterate over the list 
to find the thread with highest priority. We impleneted it that way,
because it was simple to implement and didn't impact the performance
drastically.
Inserting in the ready_list in an ordered way, is not a good solution
too, since priorities change over time, to we will have to sort the list
frequently.
64 queues seemed too much.
We think that a better approach would be 8~12 queues, each queue 
holds threads having priority in a certain range. This implementation
gets the best of the two worlds.


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

Implementing fixed point using 32 bits int was a simple yet an effective
way, it uses bit shifitng, and the arithmetic operations were not hard
to figure out and verify.
We did create an abstraction level for 2 main reasons:
1-Encapsulation: hiding the details of the implementation and providing 
an abstraction layer decouples the fixed point implementation from 
the OS code, making it easier for any future changes or adjustments.
2-Bug fixing: writing the code in one place makes it easier for bugs
detection and fixing.  

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
